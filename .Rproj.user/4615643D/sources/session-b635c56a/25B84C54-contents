---
title: "user_study"
format:
  html:
    toc: true
    html-math-method: katex
    css: styles.css
editor: visual
---

## Setup

```{r, include=FALSE}
# upload to the git
library(readxl)
library(foreach)
library(stringr)
library(dplyr)
library(tokenizers)
library(data.table)
library(ggplot2)
library(plyr)
library(quanteda)
library(SemNetCleaner)
library(purrr)
library(tidytext)
library(tm)
library(topicmodels)
library(SnowballC)
library(Matrix)
library(text2vec)
library(tidyr)
library(GGally)

```

```{r, include=FALSE}
data <- read_excel("data/results-survey3.xlsx")
data <- data[1:121] %>% 
  filter(.[[18]] !='Yes') # not analysed any EEG method
```

## Bio stats

Country

```{r}
as.data.frame(table(data[8])) %>% arrange(desc(Freq)) #%>% View()

```

Field

```{r}
field <- as.data.frame(table(data[9])) %>% arrange(desc(Freq)) %>% head(3)
field$Freq[1] <- field$Freq[1] + 1 # from Others
field$Freq[2] <- field$Freq[2] + 1
field$Freq[3] <- field$Freq[3] + 1
field
```

```{r, include=FALSE}
as.data.frame(na.omit(data[10])) 
# recode!!! 
```

### Area

```{r}
t <- foreach(i = 1:nrow(data)) %do% tokenize_words(as.character(data[i, 11]))
tt <- foreach(i = 1:length(t)) %do% paste(unlist(t[i]), collapse = ' ') 


area <- data.frame(matrix(tt)) %>% dplyr::rename(words = !!names(.)[1]) %>%
  mutate(words = ifelse(str_detect(.[[1]], 'emot|empathy'), "affective neuroscience", words)) %>%  
  #mutate(words =ifelse(str_detect(.[[1]], 'spatial'), "spatial", words)) %>% 
  mutate(words =ifelse(str_detect(.[[1]], 'memory'), "memory", words)) %>% 
  mutate(words =ifelse(str_detect(.[[1]], 'audit'), "auditory", words)) %>% 
  mutate(words =ifelse(str_detect(.[[1]], 'cognitive control|self|executive functions'), "cognitive control", words)) %>% 
  mutate(words =ifelse(str_detect(.[[1]], 'dbs'), "deep brain stimulation", words)) %>% 
  mutate(words =ifelse(str_detect(.[[1]], 'decision making|reward'), "decision making", words)) %>% 
  mutate(words =ifelse(str_detect(.[[1]], 'ageing'), "ageing", words)) %>% 
  mutate(words =ifelse(str_detect(.[[1]], 'social'), "social cognition", words)) %>% 
  mutate(words =ifelse(str_detect(.[[1]], 'olfac'), "olfaction", words)) %>% 
  mutate(words =ifelse(str_detect(.[[1]], 'language|speech|biling|english|language processing'), "language and speech", words)) %>% 
  mutate(words =ifelse(str_detect(.[[1]], 'bci'), "bci", words)) %>% 
  mutate(words =ifelse(str_detect(.[[1]], 'sleep'), "sleep", words)) %>% 
  mutate(words =ifelse(str_detect(.[[1]], 'meditation'), "meditation", words)) %>% 
  mutate(words =ifelse(str_detect(.[[1]], 'timing|time|temporal'), "time", words)) %>% 
  mutate(words =ifelse(str_detect(.[[1]], 'cognitive load|selective attention|attention|perception'), "attention and perception", words)) %>% 
  mutate(words =ifelse(str_detect(.[[1]], 'vis'), "vision", words)) %>% 
  mutate(words =ifelse(str_detect(.[[1]], 'developmental|development'), "development", words)) %>% 
  mutate(words =ifelse(str_detect(.[[1]], 'motor|motion'), "motor control", words)) %>% 
  mutate(words =ifelse(str_detect(.[[1]], 'diagnistics|disorder|psychiatry|epilepsy|autism|patients|therapy|psychopharmacology'), "mental disorders", words)) %>%   
  mutate(words =ifelse(str_detect(.[[1]], 'signal processing|event related potentials|methodology|sdf'), "dsp", words))

   
area %>% group_by(words) %>% dplyr::summarise(Freq = n()) %>% 
  data.frame(.)  %>% mutate(words = as.character(words)) %>%  #arrange(desc(Freq)) %>% 
    ggplot(data = ., aes(y = reorder(words, Freq),  x= Freq)) +
    geom_bar(stat="identity") + ylab("Words") +
    geom_text(aes(label = Freq), 
    hjust = 0)

```

### Method

```{r}
method <- data[14:17]
ch <- colnames(method)
ch1 <- foreach(i = ch) %do% str_split_i(i, "\\[", 2) 
colnames(method) <- foreach(i = ch1) %do% str_sub(i, 1, -2)
d <- data.frame(rowSums(t(data.frame(foreach(i = colnames(method)) %do% ifelse(method[i]=="Yes", 1, 0))))) 
d <- tibble::rownames_to_column(d, "plots") 
colnames(d) <- c("method", "sum_scores")
d %>% arrange(desc(sum_scores)) %>% 
    ggplot(., aes(x = method, y = sum_scores, fill = method)) +
    geom_col(stat = "identity") + labs(x = "Method", y = "Value", fill = "Method") +
    theme_classic()
```

### Experience

Papers

```{r}
ggplot(data = data, aes_(as.name(names(data)[19])))  +
  geom_histogram() +
  labs(x ="How many published papers/preprints do you have, where you used EEG, MEG or iEEG analysis?")
# PCA for clustering it 
```

Position

```{r}
#na.omit(data[13]) # recode Others
as.data.frame(table(na.omit(data[12]))) %>% dplyr::rename(position = !!names(.)[1]) %>%
  arrange(desc(Freq)) %>% 
    ggplot(data = ., aes(y = reorder(position, Freq),  x= Freq, fill = position)) +
    geom_bar(stat="identity") + ylab("Position") +
    geom_text(aes(label = Freq), 
    hjust = 0)+ theme(legend.position="none")
```

Years

```{r}
data %>% filter(.[[20]] < 50) %>% ggplot(data = ., aes_(as.name(names(data)[20]))) +
  geom_histogram() +  scale_x_continuous(breaks=seq(0, 30, 5)) +
    labs(x ="Years of experience with EEG, MEG, or iEEG analysis")
```

Self-assessed level

```{r}
table(data[21]) %>% data.frame()%>% dplyr::rename(level = !!names(.)[1]) %>%
    ggplot(data = ., aes(x = reorder(level, Freq),  y= Freq, fill = level)) +
    geom_bar(stat="identity") + xlab("Self-assessed level") +
    geom_text(aes(label = Freq), hjust = 0) + theme(legend.position="none")

```

Code contribution

```{r}
table(data[22])  %>% data.frame()%>% dplyr::rename(level = !!names(.)[1]) %>%
    ggplot(data = ., aes(x = reorder(level, Freq),  y= Freq, fill = level)) +
    geom_bar(stat="identity") + xlab("Code contribution") +
    geom_text(aes(label = Freq), hjust = 0) + theme(legend.position="none")
```

Pair plots

```{r, include=FALSE}
exp_data <- data[c(12, 19, 20:22)]
colnames(exp_data) <- c("position", "n_papers", "years", "self_level", "code_contribution")
exp_data
```

```{r}
library(FactoMineR)
library("factoextra")
#factanal(~ ., data=exp_data[2:3], factors = 2, rotation = "varimax", 
#                      na.action = na.exclude)

m =FAMD(exp_data[2:5],ncp=2,axes=c(1,2))
m$ind
fviz_famd_ind(m,col.ind = "cos2",
             gradient.cols = c("blue", "orange", "red"),
             repel = TRUE)
```

```{r}
ggpairs(exp_data[1:2]) 
```

```{r}
ggpairs(exp_data[4:5]) 
```

```{r}
ggpairs(exp_data[3:5]) 
```

```{r}
ggpairs(exp_data) 
```

### Channels

How many channels do you typically measure?

```{r}
data %>% ggplot(data = ., aes_(as.name(names(data)[23]))) +
  geom_histogram() +  scale_x_continuous(breaks=seq(0, 300, 30)) +
    labs(x ="How many channels do you typically measure?")
```

How many channels do you typically measure?

```{r}
data %>% filter(.[[24]] < 500) %>% ggplot(data = ., aes_(as.name(names(data)[24]))) +
  geom_histogram() +  scale_x_continuous(breaks=seq(0, 300, 30))+
    labs(x ="How many channels of those you measured do you typically analyse?")

# plots should be combined
```

## Software usage

#### sum

```{r}
software <- data[25:49]
ch <- colnames(software)
ch1 <- foreach(i = ch) %do% str_split_i(i, "\\[", 2) 
colnames(software) <- foreach(i = ch1) %do% str_sub(i, 1, -2)
d1 <- t(data.frame(foreach(i = colnames(software)) %do% ifelse(software[i]=="Yes", 1, 0)))
d <- data.frame(rowSums(d1)) 
d <-  tibble::rownames_to_column(d, "soft") 
colnames(d) <- c("soft", "sum_scores")
d %>% arrange(., desc(sum_scores)) -> d
d #%>% View()
# piechart and cooccuerence plot 
```

```{r}
na.omit(data[51])
```

#### cooccurence

```{r}
# how to order by diagonal matrix 
software <- data[25:49]
ch <- colnames(software)
ch1 <- foreach(i = ch) %do% str_split_i(i, "\\[", 2) 
ch1 <- foreach(i = ch1) %do% str_sub(i, 1, -2)
d1 <- foreach(i = colnames(software)) %do% ifelse(software[i]=="Yes", 1, 0)
d <- crossprod(matrix(unlist(d1), ncol = 25))
rownames(d) <- ch1
#d <- data.frame(d) 
#d$diag <- rowSums(d)
#d <- d[order(d$diag),] %>% dplyr::select(-diag)
colnames(d) <- rownames(d)
#d <- as.matrix(d)

melt(d) %>% ggplot(., aes(x=Var1, y=Var2)) + 
  geom_tile(aes(fill = value)) + 
  geom_text(aes(label = value)) +
  scale_fill_gradient(low = "white", high = "red") +
  theme(legend.title = element_blank(),
        axis.title=element_blank(),
                      axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))


```

## Important features

```{r}
features <- data[52:60]
ch <- colnames(features)
ch1 <- foreach(i = ch) %do% str_split_i(i, "\\[", 2) 
colnames(features) <- foreach(i = ch1) %do% str_sub(i, 1, -2)

features <- features %>%  mutate_at(c(colnames(features)), 
        funs(recode(.,
        "Very important"= 2, "Important"= 1, "Neutral"= 0,
        "Low importance"= -1, "Not at all important" = -2 ))) %>% 
  colSums(., na.rm =T) %>% data.frame(.) %>%  tibble::rownames_to_column(., "Feature") %>% 
  arrange(desc(.))
colnames(features) <- c("Feature", "sum_scores")
features
# divide by number of people 
# individual plots
# correlation with experience factor
```

## Familiarity with plots

```{r}

familiar <- data[61:68]
colnames(familiar) <- c("line", "butterfly", "topo", "topo_array", "topo_map", "erp_image", "parallel", "channel_image")
d <- data.frame(rowSums(t(data.frame(foreach(i = colnames(familiar)) %do% ifelse(familiar[i]=="Yes", 1, 0)))))
colnames(d) <- "sum_scores"
d %>%  tibble::rownames_to_column(., "feature") %>% arrange(desc(sum_scores)) %>% 
  ggplot(data = ., aes(y = reorder(feature, sum_scores), x= sum_scores)) +
  geom_bar(stat="identity") + ylab("feature")

# #  two bars knowing and using
```

## Have you ever plotted this king of figure

```{r}
vec <- names(data[ , grepl( "Have you ever" , names(data))]) %>% str_split_i(., "\\.....", 2) %>% as.numeric()
vec
```

```{r}

do_vec <- function(vec, data){
  t1 <- table(data[vec[1]])
  for (i in 2:length(vec)) {
    t <- table(data[vec[i]])
    t1 <- rbind(t1, t)
  }
  rownames(t1) <- array(paste0("t_", 1:length(vec)))
  return(t1)
}
tab <- do_vec(vec, data) %>%  data.frame() %>% tibble::rownames_to_column(., "plots") %>% 
  gather(., answer, score, `N.A`:`Yes`, factor_key=TRUE)

tab %>% 
  ggplot(., aes(x = plots, y = score, fill = answer)) +
    geom_bar(position = "dodge", stat = "identity") +
    labs(x = "Category", y = "Value", fill = "Group") +
    theme_classic()


```

## Up or down

```{r}
table(data[79])
```

## Error bars

```{r}
table(data[74])
```

```{r}
data[75] %>%  filter(!is.na(.)) %>% table()
```

```{r}
data[76] %>%  filter(!is.na(.)) %>% table()
```

## Baseline

### periods

```{r}
table(abs(data[77])) %>% data.frame() %>% dplyr::rename(baseline = !!names(.)[1]) %>%
    ggplot(data = ., aes(y = baseline, x= Freq)) +
    geom_bar(stat="identity") + ylab("baseline")+  scale_x_continuous(breaks=seq(0, 60, 5))
```

### justification

```{r}
# depends on what??
# manual categorization of depending
j <- data %>%    
  dplyr::rename(q = !!names(.)[78]) %>% filter(!is.na(q)) %>% dplyr::select(q) %>% 
  mutate(q = tolower(q), 
         q = gsub('.*depends in*.', 'depends on ', q),
         dependson = ifelse(grepl("depends", q), q, NA)) %>% 
  separate(dependson, into = c("a","b"), sep = "on ") %>% 
  dplyr::select(-a) %>% 
  dplyr::rename(dependson = b) #%>% 
j
  #View()
```

## Colorbars

```{r}
table(data[117])
table(data[118])
table(data[119])

```

## Feedback

```{r}
d <- data[120] %>% dplyr::rename(feed = !!names(.)[1]) %>%  filter(!is.na(feed), feed != "-") #%>% View()
```

```{r, eval = FALSE, echo = FALSE}
corpus <- VCorpus(VectorSource(d))
corpus <- corpus %>%
  tm_map(removeNumbers) %>%
  tm_map(removePunctuation) %>%
  tm_map(stripWhitespace) %>%
  tm_map(content_transformer(tolower)) %>%
  tm_map(removeWords, stopwords("english")) %>%
  tm_map(stemDocument)

corpus[[1]][[1]][1]
  
dtm <- DocumentTermMatrix(corpus)
lda <- LDA(dtm, k = 10)
terms(lda, 10)



```

## Time in minutes

```{r}
median(as.numeric(data$`Total time`)) / 60
```
